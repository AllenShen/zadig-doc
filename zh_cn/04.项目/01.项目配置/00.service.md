---
title: 服务
date: 2021-10-09 17:38:21
permalink: /project/service/
---

Zadig 的服务可以是一组 Kubernetes 资源集合（下面简称 K8s YAML）、一个完整的 Helm Chart 或者是云主机服务。包含以下几种类型：


## K8s YAML 服务

### 新增服务

项目中点击服务部分，进入服务管理页面。

![创建服务](../_images/service.png)

K8s YAML 服务的创建支持平台管理和代码仓库托管两种方式：
- `平台管理`：在创建服务时手动输入服务的 K8s YAML 配置文件，内容存储在 Zadig 系统中。
- `仓库托管`：服务的相关 K8s YAML 配置文件托管在代码仓库中，可通过在 Zadig 平台配置好 YAML 文件的目录路径后导入该部分配置。支持两种方式来从代码仓库中同步服务的 K8s YAML 配置文件：
  - 手动同步：点击`加载`按钮，获取仓库中最新的配置。
  - 自动同步：通过配置 Webhook（参阅 [Webhook 配置](/settings/webhook-config/)），Zadig 监听分支上有代码改动，对应的服务配置会被自动同步。
  > 在 Zadig <Badge text="v1.3.0"/>及以上版本中，创建服务时选择从代码库导入后，Zadig 系统会自动完成在代码平台的 Webhook 设置用于配置文件同步，用户无需再次手动配置。

#### 平台管理

* 点击新建按钮新建服务。

![创建服务](../_images/service_1.png)

* 输入新的服务名称。

![创建服务](../_images/service_2.png)

* 将服务 YAML 填入编辑器并保存。

![创建服务](../_images/service_3.png)

* 更新环境，该服务会自动加入到选择的环境中。

![更新环境](../_images/service_4.png)

#### 仓库托管

* 选择仓库托管，选择代码仓库
* 选择服务配置所在文件目录，加载服务

### 更新服务

#### 平台管理

* 修改服务 YAML 并保存。

![修改服务](../_images/service_5.png)

* 选择相应环境进行更新。

![更新环境中的服务](../_images/service_4.png)

#### 仓库托管

* 提交服务配置变更到代码仓库

![配置变更](../_images/service_upgrade_git.png)

* 变更合并到主干分支后，通过 Webhook 的能力自动同步最新配置到 Zadig 系统。也可以在界面上手动同步服务配置，如下图所示。

![服务手动配置同步](../_images/service_upgrade_manual_update.png)

* 在 Zadig 集成环境中，查看服务配置的变更，点击服务更新按钮执行更新操作

![服务版本diff](../_images/service_upgrade_diff.png)
![服务更新](../_images/service_upgrade.png)


### 删除服务

* 从`服务` 模块中将服务配置删除。
* 更新环境，将删除的服务从相应环境中移除。

![删除环境](../_images/delete_service.png)

### 变量配置

> 变量主要分为系统内置变量和自定义变量，均可在服务 YAML 中进行引用。

![变量](../_images/var.png)

添加服务或者更新服务时可创建或更新变量

#### 系统内置变量
包括 `$Namespace$`、`$Product$`、`$Service$`、`$EnvName$` ，可直接在 YAML 中进行引用，具体说明如下：

  - `$Namespace$`：项目创建的集成环境所在的 k8s 空间名称
  - `$Product$`：项目名称
  - `$Service$`：服务名称
  - `$EnvName$`：创建的集成环境名称
#### 自定义变量

通过平台新增 `Key`，可输入默认 `Value`，通过关键字：<span v-pre>`{{.key}}`</span> 引用

例如：在 K8s YAML 中引用配置的变量

```yaml
apiVersion: extensions/v1beta1
kind: Ingress
metadata:
  name: $Product$-index  //引用系统内置变量 $Product$，环境创建时被渲染
spec:
  rules:
  - host: {{.portal_host}} //引用自定义变量 portal_host，环境创建时被渲染
    http:
      paths:
      - backend:
          serviceName: $Product$-index
          servicePort: 80
        path: /
```

#### 变量的使用

##### 创建集成环境时使用

在集成环境创建时，对项目中所有服务的 YAML 和服务配置文件进行渲染。

![创建集成环境变量渲染](../_images/var_create_env.png)

##### 环境变量更新时使用

在集成环境中，对于正常运行中的服务，可以自行更新变量值，基本操作中点击`更新环境变量`，即可更新对应集成环境中的环境变量。

![更新集成环境变量渲染](../_images/var_update_env.png)

<!-- ### 共享服务
### 服务编排 -->
### 服务 YAML 样例
#### 无状态服务

概念：服务运行的实例不会在本地存储需要持久化的数据，并且多个实例对于同一个请求响应的结果是完全一致的。可以参考[这篇文章](https://kubernetes.io/zh/docs/tasks/run-application/run-stateless-application-deployment/)了解无状态服务的更多细节。
::: details
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
spec:
  selector:
    matchLabels:
      app: nginx
  replicas: 2 # 2 个 Pod 实例
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.14.2
        ports:
        - containerPort: 80
```
:::
#### 有状态服务

概念：服务的实例可以将一部分数据随时进行备份，并且在创建一个新的有状态服务时，可以通过备份恢复这些数据，以达到数据持久化的目的。可以参考[这篇文章](https://kubernetes.io/zh/docs/tasks/run-application/run-replicated-stateful-application/)了解有状态服务的更多细节。
::: details
```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: mysql
  labels:
    app: mysql
data:
  master.cnf: |
    # Apply this config only on the master.
    [mysqld]
    log-bin
  slave.cnf: |
    # Apply this config only on slaves.
    [mysqld]
    super-read-only
---
# Headless service for stable DNS entries of StatefulSet members.
apiVersion: v1
kind: Service
metadata:
  name: mysql
  labels:
    app: mysql
spec:
  ports:
  - name: mysql
    port: 3306
  clusterIP: None
  selector:
    app: mysql
---
# Client service for connecting to any MySQL instance for reads.
# For writes, you must instead connect to the master: mysql-0.mysql.
apiVersion: v1
kind: Service
metadata:
  name: mysql-read
  labels:
    app: mysql
spec:
  ports:
  - name: mysql
    port: 3306
  selector:
    app: mysql
---
apiVersion: apps/v1beta1
kind: StatefulSet
metadata:
  name: mysql
spec:
  selector:
    matchLabels:
      app: mysql
  serviceName: mysql
  # 1 master and 2 slave
  replicas: 3
  template:
    metadata:
      labels:
        app: mysql
    spec:
      initContainers:
      - name: init-mysql
        image: mysql:5.7
        command:
        - bash
        - "-c"
        - |
          set -ex
          # Generate mysql server-id from pod ordinal index.
          [[ `hostname` =~ -([0-9]+)$ ]] || exit 1
          ordinal=${BASH_REMATCH[1]}
          echo [mysqld] > /mnt/conf.d/server-id.cnf
          # Add an offset to avoid reserved server-id=0 value.
          echo server-id=$((100 + $ordinal)) >> /mnt/conf.d/server-id.cnf
          # Copy appropriate conf.d files from config-map to emptyDir.
          if [[ $ordinal -eq 0 ]]; then
            cp /mnt/config-map/master.cnf /mnt/conf.d/
          else
            cp /mnt/config-map/slave.cnf /mnt/conf.d/
          fi
        volumeMounts:
        - name: conf
          mountPath: /mnt/conf.d
        - name: config-map
          mountPath: /mnt/config-map
      - name: clone-mysql
        image: gcr.azk8s.cn/google-samples/xtrabackup:1.0
        command:
        - bash
        - "-c"
        - |
          set -ex
          # Skip the clone if data already exists.
          [[ -d /var/lib/mysql/mysql ]] && exit 0
          # Skip the clone on master (ordinal index 0).
          [[ `hostname` =~ -([0-9]+)$ ]] || exit 1
          ordinal=${BASH_REMATCH[1]}
          [[ $ordinal -eq 0 ]] && exit 0
          # Clone data from previous peer.
          ncat --recv-only mysql-$(($ordinal-1)).mysql 3307 | xbstream -x -C /var/lib/mysql
          # Prepare the backup.
          xtrabackup --prepare --target-dir=/var/lib/mysql
        volumeMounts:
        - name: data
          mountPath: /var/lib/mysql
          subPath: mysql
        - name: conf
          mountPath: /etc/mysql/conf.d
      containers:
      - name: mysql
        image: mysql:5.7
        env:
        - name: MYSQL_ALLOW_EMPTY_PASSWORD
          value: "1"
        ports:
        - name: mysql
          containerPort: 3306
        volumeMounts:
        - name: data
          mountPath: /var/lib/mysql
          subPath: mysql
        - name: conf
          mountPath: /etc/mysql/conf.d
        resources:
          requests:
            cpu: 500m
            memory: 1Gi
          limits:
            cpu: 500m
            memory: 1Gi
        livenessProbe:
          exec:
            command: ["mysqladmin", "ping"]
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 5
        readinessProbe:
          exec:
            # Check we can execute queries over TCP (skip-networking is off).
            command: ["mysql", "-h", "127.0.0.1", "-e", "SELECT 1"]
          initialDelaySeconds: 5
          periodSeconds: 2
          timeoutSeconds: 1
      - name: xtrabackup
        image: gcr.azk8s.cn/google-samples/xtrabackup:1.0
        ports:
        - name: xtrabackup
          containerPort: 3307
        command:
        - bash
        - "-c"
        - |
          set -ex
          cd /var/lib/mysql

          # Determine binlog position of cloned data, if any.
          if [[ -f xtrabackup_slave_info && "x$(<xtrabackup_slave_info)" != "x" ]]; then
            # XtraBackup already generated a partial "CHANGE MASTER TO" query
            # because we're cloning from an existing slave. (Need to remove the tailing semicolon!)
            cat xtrabackup_slave_info | sed -E 's/;$//g' > change_master_to.sql.in
            # Ignore xtrabackup_binlog_info in this case (it's useless).
            rm -f xtrabackup_slave_info xtrabackup_binlog_info
          elif [[ -f xtrabackup_binlog_info ]]; then
            # We're cloning directly from master. Parse binlog position.
            [[ `cat xtrabackup_binlog_info` =~ ^(.*?)[[:space:]]+(.*?)$ ]] || exit 1
            rm -f xtrabackup_binlog_info xtrabackup_slave_info
            echo "CHANGE MASTER TO MASTER_LOG_FILE='${BASH_REMATCH[1]}',\
                  MASTER_LOG_POS=${BASH_REMATCH[2]}" > change_master_to.sql.in
          fi

          # Check if we need to complete a clone by starting replication.
          if [[ -f change_master_to.sql.in ]]; then
            echo "Waiting for mysqld to be ready (accepting connections)"
            until mysql -h 127.0.0.1 -e "SELECT 1"; do sleep 1; done

            echo "Initializing replication from clone position"
            mysql -h 127.0.0.1 \
                  -e "$(<change_master_to.sql.in), \
                          MASTER_HOST='mysql-0.mysql', \
                          MASTER_USER='root', \
                          MASTER_PASSWORD='', \
                          MASTER_CONNECT_RETRY=10; \
                        START SLAVE;" || exit 1
            # In case of container restart, attempt this at-most-once.
            mv change_master_to.sql.in change_master_to.sql.orig
          fi

          # Start a server to send backups when requested by peers.
          exec ncat --listen --keep-open --send-only --max-conns=1 3307 -c \
            "xtrabackup --backup --slave-info --stream=xbstream --host=127.0.0.1 --user=root"
        volumeMounts:
        - name: data
          mountPath: /var/lib/mysql
          subPath: mysql
        - name: conf
          mountPath: /etc/mysql/conf.d
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
      volumes:
      - name: conf
        emptyDir: {}
      - name: config-map
        configMap:
          name: mysql
  volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      accessModes: ["ReadWriteOnce"]
      resources:
        requests:
          storage: 10Gi
```
:::

## Helm Chart 服务

> [Helm](https://helm.sh/) 是 Kubernetes 应用的包管理工具， Helm Chart 定义、安装和升级复杂的 Kubernetes 应用。

### 新增 Helm Chart

项目中点击服务部分，进入服务管理页面。
![新增 Helm Chart 服务](../_images/helm_project_overview.png)

Zadig 系统新建服务，服务配置支持三种来源：Git 仓库、Chart 仓库、模板库。

- `Git 仓库`：Helm Chart 相关配置托管于指定的 Git 仓库中，将配置从 Git 仓库中导入至 Zadig 系统内。
- `Chart 仓库`：[建设中]Helm Chart 相关配置托管于 Chart 仓库中，将配置从 Chart 仓库中导入至 Zadig 系统内。
- `模板库`：[建设中]Helm Chart 相关配置托管于 Zadig 模板库中，服务可以基于 Zadig 模板库创建。


#### Git 仓库
- 点击 `+` 新建服务，填写代码仓库相关信息及 Helm Chart 配置文件目录路径，加载服务。
> 前提: 需要先集成代码源，参考 [GitLab 集成](/settings/codehost/gitlab)/[GitHub 集成](/settings/codehost/github)

![从 Git 仓库导入 Helm Chart](../_images/helm_chart_from_git_repo.png)

<!-- #### 模板库
> 功能建设中，敬请期待……

#### Chart 仓库导入
> 功能建设中，敬请期待…… -->

### 更新服务

- 在`服务`模块，选择服务，点击“更新”按钮，重新从 Git 仓库导入服务。

![Git 仓库更新服务](../_images/helm_chart_git_update_1.png)

- 点击`更新环境`按钮，将服务添加到相应环境中。

![Git 仓库更新服务](../_images/helm_chart_git_update_2.png)

### 删除服务

- 从`服务`模块中将服务配置删除。
- 点击 `更新环境`按钮，将删除的服务从相应环境中移除。

![Git 仓库删除服务](../_images/helm_chart_git_delete.png)


## 托管项目服务
在 Zadig <Badge text="v1.5.0"/>及以上版本中，支持对 Kubernetes 集群指定命名空间的资源进行托管，实现跨集群服务管理。

### 配置托管服务
- 在托管项目中点击`环境`，进入环境管理页面，进行托管服务管理。

![托管服务](../_images/env_delegate_project_overview.png)

- 点击`配置托管`，对 `dev` 环境的服务进行管理。

![配置托管](../_images/config_service_delegation.png)

- 按需选择左侧列表中的服务拖至右侧，点击`下一步`，新增对该服务的托管管理。
> 也可通过将右侧已托管服务移至左侧来实现取消对该服务的托管管理。

![增删服务](../_images/env_delegate_add_service.png)

- 可对新加入的服务配置构建，以便使用工作流对托管的服务进行自动部署更新。


## 主机服务
在 Zadig 系统上主机服务的定义主要包括服务的构建脚本、资源配置、部署配置和探活配置。

### 新增服务

- 项目中点击服务部分，进入服务管理页面。

![新增服务](../_images/service_vm_1.png)

- 点击新建按钮新建服务。

![新增服务](../_images/service_vm_2.png)

- 输入服务名称。

![新增服务](../_images/service_vm_3.png)

### 构建脚本

- 配置构建脚本，定义服务的构建打包过程。

主机服务的构建脚本相关配置说明，参考[构建模块](/project/build/)。

### 资源配置

- 通过资源配置，关联对应集成环境使用的主机资源。

> 需事先在`系统设置` -> `主机管理` 中添加主机资源，参考[主机管理](/settings/vm-management/)。

![关联主机](../_images/service_vm_4.png)

### 部署配置

- 配置部署脚本，定义服务的部署过程。

![部署脚本](../_images/service_vm_5.png)

说明：
- 部署方式：
    - `本地直连部署`：直接在 Zadig 所在集群中执行部署操作，需确保 Zadig 系统能连通或访问到脚本中的主机地址。
    - `使用 SSH Agent 远程部署`：安全登录到目标机器，执行部署操作。
- 部署脚本和构建脚本共享存储卷，在构建脚本中生成的包在部署脚本中直接获取。
- 部署脚本可以使用构建脚本中系统内置变量，构建包需使用 `$PKG_FILE` 获取。

### 探活配置

![配置探活](../_images/service_vm_6.png)

字段说明：
- `协议`：支持 HTTP、HTTPS 和 TCP。
- `路径`：HTTP/HTTPS 请求的健康检查路径。
- `端口`：支持 1 - 65535 端口。
- `响应超时`：超出设定时间，判断为不健康。
- `高级设置`：
    - `探测间隔`：两次探活请求的间隔时间，默认 2s。
    - `健康阈值`：从不健康变为健康的连续探测次数。
    - `不健康阈值`：从健康变为不健康的连续探测次数。


### 更新服务

- 选择需要修改的服务。

![更新服务](../_images/service_vm_7.png)

- 修改服务配置，点击`保存`-> 点击`更新环境`->在弹框中选择需要更新的环境。

![更新服务](../_images/service_vm_8.png)
![更新服务](../_images/service_vm_9.png)


### 删除服务

- 从 `服务` 模块中将服务配置删除。

![删除服务](../_images/service_vm_10.png)

- 更新环境，将删除的服务从相应的环境中移除。

![删除服务](../_images/service_vm_11.png)